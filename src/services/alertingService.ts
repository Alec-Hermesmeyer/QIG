import { monitoringConfigService, MonitoringConfig, HealthHistoryPoint } from './monitoringConfig';
import { APIEndpointHealth, Alert, SystemHealth, PerformanceMetrics } from './monitoringService';

export interface AlertRule {
  id: string;
  name: string;
  description: string;
  enabled: boolean;
  conditions: AlertCondition[];
  actions: AlertAction[];
  cooldownPeriod: number; // milliseconds
  escalationRules?: EscalationRule[];
}

export interface AlertCondition {
  type: 'endpoint_status' | 'response_time' | 'availability' | 'consecutive_failures' | 'error_rate' | 'custom';
  operator: 'equals' | 'not_equals' | 'greater_than' | 'less_than' | 'greater_or_equal' | 'less_or_equal' | 'contains';
  value: any;
  timeWindow?: number; // milliseconds
  endpoint?: string; // specific endpoint or 'all'
}

export interface AlertAction {
  type: 'log' | 'display' | 'sound' | 'email' | 'webhook' | 'warmup' | 'retry';
  config: any;
}

export interface EscalationRule {
  condition: 'time_elapsed' | 'repeated_occurrence' | 'severity_increase';
  threshold: number;
  action: 'increase_severity' | 'send_notification' | 'auto_resolve' | 'trigger_warmup';
}

export interface EnhancedAlert extends Alert {
  ruleId?: string;
  occurrenceCount: number;
  firstOccurrence: string;
  lastEscalation?: string;
  autoGenerated: boolean;
  acknowledged: boolean;
  acknowledgedBy?: string;
  acknowledgedAt?: string;
  suppressUntil?: string;
  relatedEndpoints: string[];
  metadata: Record<string, any>;
}

class AlertingService {
  private activeAlerts: Map<string, EnhancedAlert> = new Map();
  private alertHistory: EnhancedAlert[] = [];
  private alertRules: AlertRule[] = [];
  private lastWarmupTime: number = 0;
  private consecutiveFailures: Map<string, number> = new Map();

  constructor() {
    this.initializeDefaultRules();
    this.loadPersistedAlerts();
  }

  /**
   * Initialize default alerting rules
   */
  private initializeDefaultRules(): void {
    const config = monitoringConfigService.getConfig();
    
    this.alertRules = [
      {
        id: 'endpoint-down',
        name: 'Endpoint Down',
        description: 'Alert when any endpoint becomes unreachable',
        enabled: true,
        conditions: [
          {
            type: 'endpoint_status',
            operator: 'equals',
            value: 'down',
            endpoint: 'all'
          }
        ],
        actions: [
          { type: 'display', config: { severity: 'critical' } },
          { type: 'log', config: { level: 'error' } }
        ],
        cooldownPeriod: 300000, // 5 minutes
        escalationRules: [
          {
            condition: 'time_elapsed',
            threshold: 600000, // 10 minutes
            action: 'trigger_warmup'
          }
        ]
      },
      {
        id: 'slow-response',
        name: 'Slow Response Times',
        description: 'Alert when response times exceed thresholds',
        enabled: true,
        conditions: [
          {
            type: 'response_time',
            operator: 'greater_than',
            value: config.alerts.thresholds.responseTime.degraded,
            timeWindow: 180000, // 3 minutes
            endpoint: 'all'
          }
        ],
        actions: [
          { type: 'display', config: { severity: 'medium' } },
          { type: 'log', config: { level: 'warn' } }
        ],
        cooldownPeriod: 180000 // 3 minutes
      },
      {
        id: 'consecutive-failures',
        name: 'Consecutive Failures',
        description: 'Alert when endpoints fail consecutively',
        enabled: true,
        conditions: [
          {
            type: 'consecutive_failures',
            operator: 'greater_or_equal',
            value: config.alerts.rules.consecutiveFailures,
            endpoint: 'all'
          }
        ],
        actions: [
          { type: 'display', config: { severity: 'high' } },
          { type: 'warmup', config: {} }
        ],
        cooldownPeriod: 600000, // 10 minutes
        escalationRules: [
          {
            condition: 'repeated_occurrence',
            threshold: 3,
            action: 'increase_severity'
          }
        ]
      },
      {
        id: 'low-availability',
        name: 'Low Availability',
        description: 'Alert when availability drops below threshold',
        enabled: true,
        conditions: [
          {
            type: 'availability',
            operator: 'less_than',
            value: config.alerts.thresholds.availability.warning,
            timeWindow: 3600000, // 1 hour
            endpoint: 'all'
          }
        ],
        actions: [
          { type: 'display', config: { severity: 'medium' } }
        ],
        cooldownPeriod: 1800000 // 30 minutes
      },
      {
        id: 'warmup-needed',
        name: 'Warmup Needed',
        description: 'Alert when APIs need warming up',
        enabled: true,
        conditions: [
          {
            type: 'custom',
            operator: 'equals',
            value: 'warmup_needed'
          }
        ],
        actions: [
          { type: 'display', config: { severity: 'low' } },
          { type: 'warmup', config: { delay: 30000 } } // Auto-warmup after 30 seconds
        ],
        cooldownPeriod: 900000 // 15 minutes
      }
    ];
  }

  /**
   * Process monitoring data and generate alerts
   */
  processMonitoringData(
    endpoints: APIEndpointHealth[],
    systemHealth: SystemHealth,
    performance: PerformanceMetrics
  ): EnhancedAlert[] {
    const config = monitoringConfigService.getConfig();
    const currentTime = Date.now();
    const generatedAlerts: EnhancedAlert[] = [];

    // Track consecutive failures
    this.updateConsecutiveFailures(endpoints);

    // Process each alert rule
    for (const rule of this.alertRules.filter(r => r.enabled)) {
      const matchingEndpoints = this.evaluateRule(rule, endpoints, systemHealth, performance);
      
      if (matchingEndpoints.length > 0) {
        const alertId = this.generateAlertId(rule, matchingEndpoints);
        const existingAlert = this.activeAlerts.get(alertId);

        // Check cooldown period
        if (existingAlert && 
            (currentTime - new Date(existingAlert.timestamp).getTime()) < rule.cooldownPeriod) {
          continue;
        }

        // Create or update alert
        const alert = this.createOrUpdateAlert(rule, matchingEndpoints, existingAlert);
        this.activeAlerts.set(alertId, alert);
        generatedAlerts.push(alert);

        // Execute alert actions
        this.executeAlertActions(rule.actions, alert);

        // Check escalation rules
        this.checkEscalationRules(rule, alert);
      }
    }

    // Check for warmup conditions
    this.checkWarmupConditions(endpoints, performance);

    // Clean up resolved alerts
    this.cleanupResolvedAlerts(endpoints);

    // Save to history
    this.persistAlerts();

    return Array.from(this.activeAlerts.values());
  }

  /**
   * Evaluate if a rule matches current conditions
   */
  private evaluateRule(
    rule: AlertRule,
    endpoints: APIEndpointHealth[],
    systemHealth: SystemHealth,
    performance: PerformanceMetrics
  ): APIEndpointHealth[] {
    const matchingEndpoints: APIEndpointHealth[] = [];

    for (const condition of rule.conditions) {
      const matches = this.evaluateCondition(condition, endpoints, systemHealth, performance);
      matchingEndpoints.push(...matches);
    }

    return [...new Set(matchingEndpoints)]; // Remove duplicates
  }

  /**
   * Evaluate a specific condition
   */
  private evaluateCondition(
    condition: AlertCondition,
    endpoints: APIEndpointHealth[],
    systemHealth: SystemHealth,
    performance: PerformanceMetrics
  ): APIEndpointHealth[] {
    const relevantEndpoints = condition.endpoint === 'all' 
      ? endpoints 
      : endpoints.filter(e => e.name === condition.endpoint);

    return relevantEndpoints.filter(endpoint => {
      switch (condition.type) {
        case 'endpoint_status':
          return this.compareValues(endpoint.health.status, condition.operator, condition.value);
        
        case 'response_time':
          if (condition.timeWindow) {
            // Check historical data for time window
            const history = monitoringConfigService.getEndpointHistory(
              endpoint.name, 
              condition.timeWindow
            );
            const avgResponseTime = history.length > 0 
              ? history.reduce((sum, h) => sum + h.responseTime, 0) / history.length
              : endpoint.health.responseTime;
            return this.compareValues(avgResponseTime, condition.operator, condition.value);
          }
          return this.compareValues(endpoint.health.responseTime, condition.operator, condition.value);
        
        case 'availability':
          return this.compareValues(endpoint.availability, condition.operator, condition.value);
        
        case 'consecutive_failures':
          const failures = this.consecutiveFailures.get(endpoint.name) || 0;
          return this.compareValues(failures, condition.operator, condition.value);
        
        case 'custom':
          return this.evaluateCustomCondition(condition, endpoint, systemHealth, performance);
        
        default:
          return false;
      }
    });
  }

  /**
   * Compare values based on operator
   */
  private compareValues(actual: any, operator: string, expected: any): boolean {
    switch (operator) {
      case 'equals':
        return actual === expected;
      case 'not_equals':
        return actual !== expected;
      case 'greater_than':
        return actual > expected;
      case 'less_than':
        return actual < expected;
      case 'greater_or_equal':
        return actual >= expected;
      case 'less_or_equal':
        return actual <= expected;
      case 'contains':
        return String(actual).includes(String(expected));
      default:
        return false;
    }
  }

  /**
   * Evaluate custom conditions
   */
  private evaluateCustomCondition(
    condition: AlertCondition,
    endpoint: APIEndpointHealth,
    systemHealth: SystemHealth,
    performance: PerformanceMetrics
  ): boolean {
    switch (condition.value) {
      case 'warmup_needed':
        const timeSinceWarmup = Date.now() - (performance.warmupStatus.lastWarmup || 0);
        return timeSinceWarmup > 600000; // 10 minutes
      
      default:
        return false;
    }
  }

  /**
   * Update consecutive failure counts
   */
  private updateConsecutiveFailures(endpoints: APIEndpointHealth[]): void {
    for (const endpoint of endpoints) {
      const current = this.consecutiveFailures.get(endpoint.name) || 0;
      
      if (endpoint.health.status === 'down') {
        this.consecutiveFailures.set(endpoint.name, current + 1);
      } else {
        this.consecutiveFailures.set(endpoint.name, 0);
      }
    }
  }

  /**
   * Create or update an alert
   */
  private createOrUpdateAlert(
    rule: AlertRule,
    endpoints: APIEndpointHealth[],
    existingAlert?: EnhancedAlert
  ): EnhancedAlert {
    const now = new Date().toISOString();
    const alertId = this.generateAlertId(rule, endpoints);

    if (existingAlert) {
      return {
        ...existingAlert,
        occurrenceCount: existingAlert.occurrenceCount + 1,
        timestamp: now,
        description: this.generateAlertDescription(rule, endpoints),
        relatedEndpoints: endpoints.map(e => e.name)
      };
    }

    return {
      id: alertId,
      ruleId: rule.id,
      type: this.determineSeverityType(rule),
      title: rule.name,
      description: this.generateAlertDescription(rule, endpoints),
      timestamp: now,
      resolved: false,
      severity: this.determineSeverity(rule, endpoints),
      occurrenceCount: 1,
      firstOccurrence: now,
      autoGenerated: true,
      acknowledged: false,
      relatedEndpoints: endpoints.map(e => e.name),
      metadata: {
        rule: rule.name,
        conditions: rule.conditions,
        endpoints: endpoints.map(e => ({
          name: e.name,
          status: e.health.status,
          responseTime: e.health.responseTime,
          error: e.health.error
        }))
      }
    };
  }

  /**
   * Generate alert description
   */
  private generateAlertDescription(rule: AlertRule, endpoints: APIEndpointHealth[]): string {
    const endpointSummary = endpoints.map(e => 
      `• ${e.name}: ${e.health.status} (${e.health.responseTime}ms)${e.health.error ? ` - ${e.health.error}` : ''}`
    ).join('\n');

    return `${rule.description}\n\nAffected Endpoints:\n${endpointSummary}\n\nRule: ${rule.name}`;
  }

  /**
   * Execute alert actions
   */
  private executeAlertActions(actions: AlertAction[], alert: EnhancedAlert): void {
    for (const action of actions) {
      try {
        switch (action.type) {
          case 'log':
            console.log(`[Alert] ${alert.title}: ${alert.description}`);
            break;
          
          case 'warmup':
            if (Date.now() - this.lastWarmupTime > 300000) { // 5 minute cooldown
              this.triggerWarmup(action.config.delay || 0);
            }
            break;
          
          case 'sound':
            this.playAlertSound(action.config);
            break;
          
          default:
            console.log(`[Alert] Unhandled action type: ${action.type}`);
        }
      } catch (error) {
        console.error(`[Alert] Failed to execute action ${action.type}:`, error);
      }
    }
  }

  /**
   * Check escalation rules
   */
  private checkEscalationRules(rule: AlertRule, alert: EnhancedAlert): void {
    if (!rule.escalationRules) return;

    for (const escalation of rule.escalationRules) {
      if (this.shouldEscalate(escalation, alert)) {
        this.executeEscalationAction(escalation, alert);
        alert.lastEscalation = new Date().toISOString();
      }
    }
  }

  /**
   * Check if alert should be escalated
   */
  private shouldEscalate(escalation: EscalationRule, alert: EnhancedAlert): boolean {
    switch (escalation.condition) {
      case 'time_elapsed':
        const elapsed = Date.now() - new Date(alert.firstOccurrence).getTime();
        return elapsed > escalation.threshold;
      
      case 'repeated_occurrence':
        return alert.occurrenceCount >= escalation.threshold;
      
      case 'severity_increase':
        // Custom logic for severity increase detection
        return false;
      
      default:
        return false;
    }
  }

  /**
   * Execute escalation action
   */
  private executeEscalationAction(escalation: EscalationRule, alert: EnhancedAlert): void {
    switch (escalation.action) {
      case 'increase_severity':
        if (alert.severity === 'low') alert.severity = 'medium';
        else if (alert.severity === 'medium') alert.severity = 'high';
        else if (alert.severity === 'high') alert.severity = 'critical';
        break;
      
      case 'trigger_warmup':
        this.triggerWarmup();
        break;
    }
  }

  /**
   * Check warmup conditions
   */
  private checkWarmupConditions(endpoints: APIEndpointHealth[], performance: PerformanceMetrics): void {
    const config = monitoringConfigService.getConfig();
    
    if (Date.now() - this.lastWarmupTime < config.alerts.rules.warmupGracePeriod) {
      return; // In warmup grace period
    }

    // Auto-warmup logic based on conditions
    const slowEndpoints = endpoints.filter(e => e.health.responseTime > 5000);
    const downEndpoints = endpoints.filter(e => e.health.status === 'down');
    
    if (config.warmup.autoWarmupEnabled && (slowEndpoints.length > 0 || downEndpoints.length > 0)) {
      const timeSinceLastWarmup = Date.now() - (performance.warmupStatus.lastWarmup || 0);
      if (timeSinceLastWarmup > config.warmup.warmupInterval) {
        this.triggerWarmup();
      }
    }
  }

  /**
   * Clean up resolved alerts
   */
  private cleanupResolvedAlerts(endpoints: APIEndpointHealth[]): void {
    const endpointNames = new Set(endpoints.map(e => e.name));
    const healthyEndpoints = new Set(
      endpoints.filter(e => e.health.status === 'healthy').map(e => e.name)
    );

    for (const [alertId, alert] of this.activeAlerts.entries()) {
      // Check if all related endpoints are now healthy
      const allEndpointsHealthy = alert.relatedEndpoints.every(name => 
        healthyEndpoints.has(name)
      );

      if (allEndpointsHealthy && !alert.resolved) {
        alert.resolved = true;
        alert.timestamp = new Date().toISOString();
        this.alertHistory.push(alert);
        this.activeAlerts.delete(alertId);
      }
    }
  }

  /**
   * Trigger warmup with cooldown
   */
  private async triggerWarmup(delay: number = 0): Promise<void> {
    try {
      if (delay > 0) {
        setTimeout(() => this.triggerWarmup(0), delay);
        return;
      }

      // Import warmup service dynamically to avoid circular dependencies
      const { apiWarmupService } = await import('./apiWarmupService');
      await apiWarmupService.warmupApis();
      this.lastWarmupTime = Date.now();
      
      console.log('[Alert] Auto-warmup triggered by alerting system');
    } catch (error) {
      console.error('[Alert] Failed to trigger warmup:', error);
    }
  }

  /**
   * Play alert sound
   */
  private playAlertSound(config: any): void {
    if (typeof window !== 'undefined' && window.AudioContext) {
      try {
        const audioContext = new AudioContext();
        const oscillator = audioContext.createOscillator();
        const gainNode = audioContext.createGain();
        
        oscillator.connect(gainNode);
        gainNode.connect(audioContext.destination);
        
        oscillator.frequency.setValueAtTime(config.frequency || 800, audioContext.currentTime);
        gainNode.gain.setValueAtTime(config.volume || 0.3, audioContext.currentTime);
        
        oscillator.start(audioContext.currentTime);
        oscillator.stop(audioContext.currentTime + (config.duration || 0.2));
      } catch (error) {
        console.warn('[Alert] Could not play sound:', error);
      }
    }
  }

  /**
   * Generate unique alert ID
   */
  private generateAlertId(rule: AlertRule, endpoints: APIEndpointHealth[]): string {
    const endpointNames = endpoints.map(e => e.name).sort().join('-');
    return `${rule.id}-${endpointNames}`;
  }

  /**
   * Determine alert severity type
   */
  private determineSeverityType(rule: AlertRule): 'error' | 'warning' | 'info' {
    const action = rule.actions.find(a => a.type === 'display');
    const severity = action?.config?.severity || 'medium';
    
    switch (severity) {
      case 'critical':
      case 'high':
        return 'error';
      case 'medium':
        return 'warning';
      default:
        return 'info';
    }
  }

  /**
   * Determine alert severity
   */
  private determineSeverity(rule: AlertRule, endpoints: APIEndpointHealth[]): 'low' | 'medium' | 'high' | 'critical' {
    const action = rule.actions.find(a => a.type === 'display');
    return action?.config?.severity || 'medium';
  }

  /**
   * Acknowledge an alert
   */
  acknowledgeAlert(alertId: string, acknowledgedBy: string): boolean {
    const alert = this.activeAlerts.get(alertId);
    if (alert) {
      alert.acknowledged = true;
      alert.acknowledgedBy = acknowledgedBy;
      alert.acknowledgedAt = new Date().toISOString();
      this.persistAlerts();
      return true;
    }
    return false;
  }

  /**
   * Suppress an alert for a specified duration
   */
  suppressAlert(alertId: string, durationMs: number): boolean {
    const alert = this.activeAlerts.get(alertId);
    if (alert) {
      alert.suppressUntil = new Date(Date.now() + durationMs).toISOString();
      this.persistAlerts();
      return true;
    }
    return false;
  }

  /**
   * Get active alerts (not suppressed)
   */
  getActiveAlerts(): EnhancedAlert[] {
    const now = Date.now();
    return Array.from(this.activeAlerts.values()).filter(alert => 
      !alert.suppressUntil || new Date(alert.suppressUntil).getTime() < now
    );
  }

  /**
   * Get alert rules
   */
  getAlertRules(): AlertRule[] {
    return [...this.alertRules];
  }

  /**
   * Update alert rule
   */
  updateAlertRule(ruleId: string, updates: Partial<AlertRule>): boolean {
    const ruleIndex = this.alertRules.findIndex(r => r.id === ruleId);
    if (ruleIndex >= 0) {
      this.alertRules[ruleIndex] = { ...this.alertRules[ruleIndex], ...updates };
      this.persistAlerts();
      return true;
    }
    return false;
  }

  /**
   * Add custom alert rule
   */
  addAlertRule(rule: AlertRule): void {
    this.alertRules.push(rule);
    this.persistAlerts();
  }

  /**
   * Remove alert rule
   */
  removeAlertRule(ruleId: string): boolean {
    const initialLength = this.alertRules.length;
    this.alertRules = this.alertRules.filter(r => r.id !== ruleId);
    
    if (this.alertRules.length < initialLength) {
      this.persistAlerts();
      return true;
    }
    return false;
  }

  /**
   * Get alert history
   */
  getAlertHistory(timeRange?: number): EnhancedAlert[] {
    let history = [...this.alertHistory];
    
    if (timeRange) {
      const cutoff = Date.now() - timeRange;
      history = history.filter(alert => 
        new Date(alert.timestamp).getTime() > cutoff
      );
    }
    
    return history.sort((a, b) => 
      new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime()
    );
  }

  /**
   * Persist alerts to localStorage
   */
  private persistAlerts(): void {
    try {
      const data = {
        activeAlerts: Array.from(this.activeAlerts.entries()),
        alertHistory: this.alertHistory.slice(-100), // Keep last 100 resolved alerts
        alertRules: this.alertRules,
        consecutiveFailures: Array.from(this.consecutiveFailures.entries())
      };
      
      localStorage.setItem('qig_alerting_data', JSON.stringify(data));
    } catch (error) {
      console.error('[Alert] Failed to persist alerts:', error);
    }
  }

  /**
   * Load persisted alerts
   */
  private loadPersistedAlerts(): void {
    try {
      const stored = localStorage.getItem('qig_alerting_data');
      if (stored) {
        const data = JSON.parse(stored);
        
        if (data.activeAlerts) {
          this.activeAlerts = new Map(data.activeAlerts);
        }
        
        if (data.alertHistory) {
          this.alertHistory = data.alertHistory;
        }
        
        if (data.alertRules) {
          // Merge with default rules, preserving custom rules
          const customRules = data.alertRules.filter((rule: AlertRule) => 
            !this.alertRules.some(defaultRule => defaultRule.id === rule.id)
          );
          this.alertRules.push(...customRules);
        }
        
        if (data.consecutiveFailures) {
          this.consecutiveFailures = new Map(data.consecutiveFailures);
        }
      }
    } catch (error) {
      console.error('[Alert] Failed to load persisted alerts:', error);
    }
  }
}

// Export singleton instance
export const alertingService = new AlertingService();

// Export class for testing
export { AlertingService }; 